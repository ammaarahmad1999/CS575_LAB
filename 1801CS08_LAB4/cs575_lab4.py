# -*- coding: utf-8 -*-
"""CS575_LAB4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WM8jds9aTlH_DIKIEbDL5eBKfIixn0Qj
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats
from scipy.stats import norm, pearsonr, skew, kurtosis
import math
import pandas as pd
from statsmodels.graphics.gofplots import qqplot
plt.style.use('ggplot')

from scipy.stats import f_oneway

from numpy import mean
from math import sqrt
from scipy.stats import sem, t

"""#**Task 1**

## Task 1
An organization recruits 30 students to participate in a study. For next 4 weeks, the students are randomly assigned to use one of the 3 studying approaches to prepare for an exam. At the end of the training period, all students take same each group.  Following are the exam scores for each group:

<img width="444" height="555" alt="Screenshot 2021-09-15 at 1 36 16 PM" src="https://user-images.githubusercontent.com/43731599/133395598-1c56714d-f9dd-466b-ae8c-0a8f25a2c69f.png">
"""

group1=np.array([85,86,88,75,78,94,98,79,71,80])
group2=np.array([79,78,88,94,92,85,83,85,82,81])
group3=np.array([91,92,93,85,87,84,82,88,95,96])

"""#Q1"""

def calculate(group):
  
  length = len(group)
  group = np.sort(group)
  mean = sum(group)/length
  if (length%2):
    median = group[length//2]
  else:
    median = (group[length//2] + group[length//2 - 1])/2

  variance = sum((group - mean)**2)/length
  std = sqrt(variance)
  skewness = sum((group - mean)**3)/(length*std**3)
  kurtosis_value = sum((group - mean)**4)/(length*variance*variance)
  kurtosis_value = kurtosis_value - 3

  return mean, median, variance, std, skewness, kurtosis_value

"""Group1"""

mean, median, variance, std, skewness, kurtosis_value = calculate(group1)
print(f'Mean = {mean}, Median = {median}')
print(f'Variance = {variance}, Standard Deviation = {std}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

mean, median, skewness, kurtosis_value = np.mean(group1), np.median(group1), skew(group1), kurtosis(group1)
print(f'Mean = {mean}, Median = {median}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

"""Group2"""

mean, median, variance, std, skewness, kurtosis_value = calculate(group2)
print(f'Mean = {mean}, Median = {median}')
print(f'Variance = {variance}, Standard Deviation = {std}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

mean, median, skewness, kurtosis_value = np.mean(group2), np.median(group2), skew(group2), kurtosis(group2)
print(f'Mean = {mean}, Median = {median}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

"""Group3"""

mean, median, variance, std, skewness, kurtosis_value = calculate(group3)
print(f'Mean = {mean}, Median = {median}')
print(f'Variance = {variance}, Standard Deviation = {std}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

mean, median, skewness, kurtosis_value = np.mean(group3), np.median(group3), skew(group3), kurtosis(group3)
print(f'Mean = {mean}, Median = {median}')
print(f'Skewness = {skewness}, Kurtosis = {kurtosis_value}')

"""#Q2"""

from numpy import mean

#Calculate Mean of each group
m1 = np.mean(group1)
m2 = np.mean(group2)
m3 = np.mean(group3)

#Overall Mean
m = (m1+m2+m3)/3

#Between Group mean sum of squares
SSB=10*((m1-m)**2+(m2-m)**2+(m3-m)**2)
MSB=SSB/2

#Within Group mean sum of squares
SSW = np.sum((group1 - m1)**2) + np.sum((group2 - m2)**2) + np.sum((group3 - m3)**2)
MSW = SSW/27

#Calculate F Statistics
F = MSB/MSW

from scipy.stats import f
p = 1-f.cdf(F, 2, 27)
print(f'F-statistic = {F}, P-value = {p}')

"""we compare this to the F critical value found in the F distribution table with the values :\
Î± (significance level) = 0.05\
DF1 (numerator degrees of freedom) = 2\
DF2 (denominator degrees of freedom) = 27

If the F test statistic in the ANOVA table is less than the F critical value in the F distribution table, then we fail to reject the null hypothesis.

P-value > 0.05 (significance value) hence we fail to reject the null hyptohesis

#Q3
"""

stats.f_oneway(group1,group2,group3)

"""P value > 0.05 indicates that there is possibility of mean of 3 groups being from same distribution and hence we cannot reject the Null hypothesis

#**Task2**

#Q1
"""

df = pd.read_csv("https://raw.githubusercontent.com/ammaarahmad1999/Time_Series_Dataset/main/stcp-Rdataset-Diet.csv")

df.sample(10)

df[df['gender'] == ' ']

df = df[df['gender'] != ' ']

df['gender'].value_counts()

axl = df.plot(kind='scatter', x='Person', y='pre.weight', color='blue', alpha=0.5, figsize=(12, 8))
plt.title('Scatter Plot of Pre-weight of distribution', size=20)
plt.xlabel('Person', size=18)
plt.ylabel('Weight', size=18)

df = df.apply(pd.to_numeric)
df.dtypes

axl = df[df['gender'] == 1].plot(kind='scatter', x='Person', y='pre.weight', color='blue', alpha=0.5, figsize=(12, 8))
plt.title('Scatter Plot of Pre-weight distribution of Males', size=20)
plt.xlabel('Person', size=18)
plt.ylabel('Weight', size=18)

axl = df[df['gender'] == 0].plot(kind='scatter', x='Person', y='pre.weight', color='magenta', alpha=0.5, figsize=(12, 8))
plt.title('Scatter Plot of Pre-weight distribution of Females', size=20)
plt.xlabel('Person', size=18)
plt.ylabel('Weight', size=18)

# Scatter plot of Diet and Female Pre-Weight
ax1 = df[df['gender'] == 1].plot(kind='scatter', x='Diet', y='pre.weight', color='blue', alpha=0.5, figsize=(12, 8))
plt.title('Relationship between Diet and Pre-Weight in Males', size=24)
plt.xlabel('Diet', size=18)
plt.ylabel('Pre-Weight', size=18)

# Scatter plot of Diet and Female weight6weeks
ax1 = df[df['gender'] == 0].plot(kind='scatter', x='Diet', y='pre.weight', color='magenta', alpha=0.5, figsize=(12, 8))
plt.title('Relationship between Diet and Pre-Weight in Females', size=24)
plt.xlabel('Diet', size=18)
plt.ylabel('Pre-Weight', size=18)

df_male = df[df['gender'] == 1]
df_male.describe()

df_male = df[df['gender'] == 0]
df_male.describe()

"""#Q2"""

f_oneway(df[df['Diet']==1]['pre.weight'], df[df['Diet']==2]['pre.weight'], df[df['Diet']==3]['pre.weight'])

"""Pvalue of 0.29 give significant evidence that we cannot reject null hypothesis"""

f_oneway(df[df['Diet']==1]['weight6weeks'], df[df['Diet']==2]['weight6weeks'], df[df['Diet']==3]['weight6weeks'])

"""Pvalue of 0.54 give significant evidence that we cannot reject null hypothesis

#**Task 3**
"""

df = pd.read_csv("https://raw.githubusercontent.com/researchpy/Data-sets/master/blood_pressure.csv")

df.sample(10)

"""#Q1"""

axl = df[df['sex'] == "Male"].plot(kind='scatter', x = 'patient',  y='bp_after', color='blue', alpha=0.5, figsize=(12, 8))
df[df['sex'] == "Female"].plot(kind='scatter', x='patient', y='bp_after', color='magenta', alpha=0.5, figsize=(12, 8), ax = axl)
plt.legend(labels=['Males', 'Females'])
plt.title('Scatter Plot of Post Blood Pressure', size=20)
plt.xlabel('Patient', size=18)
plt.ylabel('Post-BP', size=18)

"""#Q2"""

df_male = df[df['sex'] == 'Male'].set_index('patient')
df_female = df[df['sex'] == 'Female'].set_index('patient')

# Descriptive statistics male
statistics_male = df_male.describe()
statistics_male.rename(columns=lambda x: x + '_male', inplace=True)

# Descriptive statistics female
statistics_female = df_female.describe()
statistics_female.rename(columns=lambda x: x + '_female', inplace=True)

# Dataframe that contains statistics for both male and female
statistics = pd.concat([statistics_male, statistics_female], axis=1)
statistics

"""#Q3

Null Hypothesis : Mean of blood pressure for both male and female are equal

Alternate Hypothesis : Mean of blood pressure for both male and female are different
"""

# Example of the Student's t-test
from scipy.stats import ttest_ind

stat, p = ttest_ind(df_male['bp_after'], df_female['bp_after'])
print('stat=%.3f, p=%.3f' % (stat, p))
if p > 0.05:
	print('Probably the same distribution')
else:
	print('Probably different distributions')

# function for calculating the t-test for two independent samples
def independent_ttest(data1, data2, alpha):
	# calculate means
	mean1, mean2 = mean(data1), mean(data2)
	# calculate standard errors
	se1, se2 = sem(data1), sem(data2)
	# standard error on the difference between the samples
	sed = sqrt(se1**2.0 + se2**2.0)
	# calculate the t statistic
	t_stat = (mean1 - mean2) / sed
	# degrees of freedom
	df = len(data1) + len(data2) - 2
	# calculate the critical value
	cv = t.ppf(1.0 - alpha, df)
	# calculate the p-value
	p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0
	# return everything
	return t_stat, df, cv, p

# calculate the t test
alpha = 0.05
t_stat, df, cv, p = independent_ttest(df_male['bp_after'], df_female['bp_after'], alpha)
print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))
# interpret via critical value
if abs(t_stat) <= cv:
	print('Accept null hypothesis that the means are equal.')
else:
	print('Reject the null hypothesis that the means are equal.')
# interpret via p-value
if p > alpha:
	print('Accept null hypothesis that the means are equal.')
else:
	print('Reject the null hypothesis that the means are equal.')

"""We got t value as 3.348 and p = 0.001 which is less than significance level hence rejecting the Null Hypothesis

#**Task 4**
"""

df = pd.read_csv('/content/drive/MyDrive/sp500_data.csv')

df = df[['CVX', 'XOM']]

def sample_mean(df, sample_size):
  sample_means = []
  for i in range(1000):
      df_temp = df.sample(sample_size)
      sample_means.append(df_temp.mean())
  return sample_means

sample_means = sample_mean(df['CVX'], 100)
mn = np.mean(sample_means)
std = np.std(sample_means)
plt.hist(sample_means, density = True)
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.xlabel('Sample_Mean')
plt.ylabel('Probability Density')
plt.show()

s = pd.Series(sample_means)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

sample_means = sample_mean(df['CVX'], 500)
mn = np.mean(sample_means)
std = np.std(sample_means)
plt.hist(sample_means, density = True)
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.xlabel('Sample_Mean')
plt.ylabel('Probability Density')
plt.show()

s = pd.Series(sample_means)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

sample_means = sample_mean(df['CVX'], 1000)
mn = np.mean(sample_means)
std = np.std(sample_means)
plt.hist(sample_means, density = True)
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.xlabel('Sample_Mean')
plt.ylabel('Probability Density')
plt.show()

s = pd.Series(sample_means)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

"""We observed that on increasing the sample size from 100 to 500 to 1000 the standard deviation of sample mean decreases.

#**Task 5**
"""

def sample_std(df, sample_size):
  sample_dev = []
  for i in range(1000):
      df_temp = df.sample(sample_size)
      sample_dev.append(df_temp.std())
  return sample_dev

sample_dev = sample_std(df['XOM'], 100)
mn = np.mean(sample_dev)
std = np.std(sample_dev)
plt.hist(sample_dev, density = True)
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.xlabel('Sample_Mean')
plt.ylabel('Probability Density')
plt.show()

s = pd.Series(sample_dev)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

"""On sampling standard deviation values on XOM sp500 values. We found that it is highly positively skewed

#**Task 6**
"""

def probability_red(probability, no_of_experiments):
  outcomes = []
  rng = np.random.RandomState(1)
  for i in range(no_of_experiments):
    dice_rolls = rng.choice(np.arange(4), size = 100, p=probability)
    num_six = (dice_rolls == 0).sum()
    outcomes.append(num_six)
  return outcomes

outcomes = probability_red([0.25, 0.25, 0.25, 0.25], 10000)
mn = np.mean(outcomes)
std = np.std(outcomes)
plt.hist(outcomes, density=True)
plt.xlabel('Number of Red Balls')
plt.ylabel('Probability of outcome')
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.show()

s = pd.Series(outcomes)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

outcomes = probability_red([0.7, 0.1, 0.1, 0.1], 10000)
mn = np.mean(outcomes)
std = np.std(outcomes)
plt.hist(outcomes, density=True)
plt.xlabel('Number of Red Balls')
plt.ylabel('Probability of outcome')
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')
plt.show()

s = pd.Series(outcomes)
mn = s.mean()
std = s.std()
ax = s.plot.kde()
plt.axvline(mn, color='blue')
plt.axvline(mn-2*std, color = 'black')
plt.axvline(mn+2*std, color = 'black')

"""We observed that the mean percentage of red balls is nearly equal to actual percentage of red balls in the bag. This is expected as no. of experiments done is large = 10000"""